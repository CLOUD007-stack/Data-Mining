{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e72f05b",
   "metadata": {},
   "source": [
    "# DM-Practical-02  A - Datawarehouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf8b3c",
   "metadata": {},
   "source": [
    "### Q1: Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DW_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b720c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Title'] = df['Job Title'].str.strip()\n",
    "df['Gender'] = df['Gender'].str.strip()\n",
    "df[['Address', 'County']] = df[\"Address\"].str.split(r\"\\bCo\\b\", expand=True)\n",
    "df['County'] = df['County'].str.replace(r'.', \"\", regex=True)\n",
    "df['Date of Birth'] = pd.to_datetime(df['Date of Birth'], infer_datetime_format=True)\n",
    "df['Date Joined'] = pd.to_datetime(df['Date Joined'], infer_datetime_format=True)\n",
    "df['Date Left'] = pd.to_datetime(df['Date Left'], infer_datetime_format=True)\n",
    "\n",
    "\n",
    "def getJobCategory(x):\n",
    "    y = x.split(' ')\n",
    "    if 'Technician' in y:\n",
    "        return 'Technical'\n",
    "    elif 'Director' in y:\n",
    "        return 'Management'\n",
    "    elif 'Manager' in y:\n",
    "        return 'Management'\n",
    "\n",
    "df['Job Category'] = df[\"Job Title\"].apply(getJobCategory)\n",
    "df = df.drop(['Address', 'Job Title'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c939fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating - PSQL database and engine\n",
    "engine = create_engine('postgresql://postgres:root@localhost:5432/postgres')\n",
    "\n",
    "# Storing DataFrame-df into PSQL database\n",
    "df.to_sql('employee_data', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "sess = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12cd044",
   "metadata": {},
   "source": [
    "1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = text(''' \n",
    "SELECT \"Gender\", AVG(\"Salary\") AS avg_salary \n",
    "FROM employee_data\n",
    "WHERE \"Job Category\" = 'Management'\n",
    "GROUP BY \"Gender\"\n",
    "''')\n",
    "\n",
    "result1 = engine.execute(Q1)\n",
    "\n",
    "for row in result1:\n",
    "    print(f'Average Salary {row[\"Gender\"]} = {row[\"avg_salary\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7cb76",
   "metadata": {},
   "source": [
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = text(''' \n",
    "SELECT \"County\", AVG(\"Salary\") as \"avg_salary\" \n",
    "FROM employee_data \n",
    "GROUP BY \"County\" ''')\n",
    "\n",
    "query2 = text(''' \n",
    "SELECT \"Gender\", \"County\", AVG(\"Salary\") as \"avg_salary\" \n",
    "FROM employee_data \n",
    "GROUP BY \"Gender\", \"County\" ''')\n",
    "\n",
    "result1 = sess.execute(query1)\n",
    "result2 = sess.execute(query2)\n",
    "\n",
    "print(\"Average salaries Employees From Kildare and Dublin : \\n\")\n",
    "\n",
    "for row in result1:\n",
    "    county = row[0]\n",
    "    average_salary = row[1]\n",
    "    print(f\"{county}: {average_salary:.2f}\")\n",
    "\n",
    "print(\"\\nAverage salary by Gender and County : \\n\")\n",
    "\n",
    "for row in result2:\n",
    "    gender=row[0]\n",
    "    county = row[1]\n",
    "    average_salary = row[2]\n",
    "    print(f\"{gender} {county}: {average_salary:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e33d27",
   "metadata": {},
   "source": [
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de113602",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1970 = ('''\n",
    "SELECT COUNT(*)\n",
    "FROM employee_data\n",
    "WHERE EXTRACT(YEAR FROM \"Date of Birth\") BETWEEN 1970 AND 1979\n",
    "AND (\"Date Left\" IS NULL OR \"Date Left\" >= '2022-12-31');\n",
    "''')\n",
    "\n",
    "query_1980 = ('''\n",
    "SELECT COUNT(*)\n",
    "FROM employee_data\n",
    "WHERE EXTRACT(YEAR FROM \"Date of Birth\") BETWEEN 1980 AND 1989\n",
    "AND (\"Date Left\" IS NULL OR \"Date Left\" >= '2022-12-31');\n",
    "''')\n",
    "\n",
    "query_1990 = ('''\n",
    "SELECT COUNT(*)\n",
    "FROM employee_data\n",
    "WHERE EXTRACT(YEAR FROM \"Date of Birth\") BETWEEN 1990 AND 1999\n",
    "AND (\"Date Left\" IS NULL OR \"Date Left\" >= '2022-12-31');\n",
    "''')\n",
    "\n",
    "\n",
    "result1 = sess.execute(query_1970).scalar()\n",
    "result2 = sess.execute(query_1980).scalar()\n",
    "result3 = sess.execute(query_1990).scalar()\n",
    "\n",
    "\n",
    "# Results\n",
    "print(f\"Employees born in the 1970 and are working upto 2022: {result1}\")\n",
    "print(f\"Employees born in the 1980 and are working upto 2022: {result2}\")\n",
    "print(f\"Employees born in the 1990 and are working upto 2022: {result3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d1f33",
   "metadata": {},
   "source": [
    "4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2001, 2002]\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    begin_year = (f'''\n",
    "    SELECT COUNT(*)\n",
    "    FROM employee_data\n",
    "    WHERE \"Date Joined\" <= '{year}-01-01';\n",
    "    ''')\n",
    "   \n",
    "    retained_year = (f'''\n",
    "    SELECT COUNT(*)\n",
    "    FROM employee_data\n",
    "    WHERE \"Date Joined\" <= '{year}-01-01'\n",
    "    AND (\"Date Left\" IS NULL OR \"Date Left\" >= '{year}-12-31');\n",
    "    ''')\n",
    "\n",
    "    beginning_of_year = sess.execute(begin_year).scalar()\n",
    "    retained_in_year = sess.execute(retained_year).scalar()\n",
    "\n",
    "    retention_rate = (retained_in_year / beginning_of_year) * 100\n",
    "    print(f\"Employee retention rate in {year}: {retention_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf00fc8",
   "metadata": {},
   "source": [
    "5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee58cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [\n",
    "    {'s': '2001-01-01', 'e': '2001-03-31'},\n",
    "    {'s': '2001-04-01', 'e': '2001-06-30'},\n",
    "    {'s': '2001-07-01', 'e': '2001-09-30'},\n",
    "    {'s': '2001-10-01', 'e': '2001-12-31'},\n",
    "    {'s': '2002-01-01', 'e': '2002-03-31'},\n",
    "    {'s': '2002-04-01', 'e': '2002-06-30'},\n",
    "    {'s': '2002-07-01', 'e': '2002-09-30'},\n",
    "    {'s': '2002-10-01', 'e': '2002-12-31'}\n",
    "]\n",
    "\n",
    "for quarter in q:\n",
    "    s = quarter['s']\n",
    "    e = quarter['e']\n",
    "    \n",
    "    y = s[:4]\n",
    "\n",
    "    qs = text(f'''\n",
    "    SELECT COUNT(*) FROM employee_data \n",
    "    WHERE \"Date Joined\" <= '{s}' \n",
    "    AND (\"Date Left\" IS NULL OR \"Date Left\" > '{s}') \n",
    "    ''')\n",
    "    \n",
    "    rs = engine.execute(qs)\n",
    "    js = rs.scalar()\n",
    "    \n",
    "    qe = text(f'''\n",
    "    SELECT COUNT(*) FROM employee_data \n",
    "    WHERE \"Date Joined\" <= '{s}' \n",
    "    AND (\"Date Left\" IS NULL OR \"Date Left\" > '{e}') \n",
    "    ''')\n",
    "    \n",
    "    re = engine.execute(qe)\n",
    "    le = re.scalar()\n",
    "    \n",
    "    r = (le / js) * 100\n",
    "    \n",
    "    print(f\"Retention Rate {y}: {r:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4f965",
   "metadata": {},
   "source": [
    "### Q2: Data Warehouse - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6bd88",
   "metadata": {},
   "source": [
    "1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename='Snowflake.png',width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3afd4e",
   "metadata": {},
   "source": [
    "2) \n",
    "\n",
    "### Methods such as following OLAP operation Explaination :\n",
    "\n",
    "Starting from the base cuboid [student, course, semester, instructor], \n",
    "We can do the following OLAP operations to get the average grade for each Big University student's Computer Science (CS) courses:\n",
    "\n",
    "#### Method 1 : \n",
    "Roll-up from Semester to Year: This process adds up the grades for every student and computer science course year by year in order to aggregate the data. We can use this to find the average grade for each year's CS courses.\n",
    "\n",
    "#### Method 2 :\n",
    "Drill-down from Year to Semester: If more information is needed, you can carry out the opposite process to drill down to the semester level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a229deb",
   "metadata": {},
   "source": [
    "3 )\n",
    "\n",
    "When there are four dimensions and five levels in each dimension (including \"all\"), \n",
    "The total number of cuboids—including base and apex cuboids—can be computed as follows:\n",
    "\n",
    "#### Five levels per dimension multiplied by four equals 625 cuboids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465459d",
   "metadata": {},
   "source": [
    "4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c52ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input_DW_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:root@localhost:5432/postgres')\n",
    "\n",
    "# Storing DataFrame-df into PSQL database\n",
    "df.to_sql('student_data', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ea33c",
   "metadata": {},
   "source": [
    "5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef63081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "def read_record(Table, Field, Value, engine):\n",
    "    query = f\"SELECT * FROM {Table} WHERE {Field} = '{Value}'\"\n",
    "    result = engine.execute(query)\n",
    "    return result.fetchall()\n",
    "\n",
    "result_df = pd.DataFrame(read_record('student_data', 'course', 'CS', engine))\n",
    "print(\"Reading Records:\\n\\n\",result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write record \n",
    "def write_record(Table, data_dict, engine):\n",
    "    # Insert record into the database\n",
    "    keys = ','.join(data_dict.keys())\n",
    "    values = ','.join([f\"'{value}'\" for value in data_dict.values()])\n",
    "    query = f\"INSERT INTO {Table} ({keys}) VALUES ({values})\"\n",
    "    \n",
    "    engine.execute(query)\n",
    "\n",
    "data_to_insert = {\n",
    "    'name': 'Aakash',\n",
    "    'course': 'CS',\n",
    "    'semester': '3',\n",
    "    'instructor': 'Z',\n",
    "    'avg_grade': '5'\n",
    "}\n",
    "write_record('student_data', data_to_insert, engine)\n",
    "\n",
    "\n",
    "query = \"SELECT * FROM student_data\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update record \n",
    "def update_record(engine, table_name, update_data, condition_column, condition_value):\n",
    "        update_query = f\"UPDATE {table_name} SET \"\n",
    "        update_query += ', '.join([f\"{column} = '{value}'\" for column, value in update_data.items()])\n",
    "        update_query += f\" WHERE {condition_column} = '{condition_value}'\"\n",
    "\n",
    "        engine.execute(update_query)\n",
    "\n",
    "# Updated Record Value \n",
    "update_data = {'avg_grade': 20}  \n",
    "condition_column = 'name'\n",
    "condition_value = 'Aakash' \n",
    "\n",
    "update_record(engine, 'student_data', update_data, condition_column, condition_value)\n",
    "\n",
    "query = \"SELECT * FROM student_data\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset Full\n",
    "def read_dataset(name, engine):\n",
    "    query = f\"SELECT * FROM {name}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df\n",
    "\n",
    "fulldf = read_dataset('student_data', 'postgresql://postgres:root@localhost:5432/postgres')\n",
    "fulldf\n",
    "\n",
    "query = \"SELECT * FROM student_data\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataset\n",
    "def write_dataset(name, dataset, engine):\n",
    "    dataset.to_sql(name, engine, if_exists='append', index=False)\n",
    "\n",
    "data_to_write = pd.DataFrame({'name': ['E', 'F'], 'course': ['CS', 'Eng'], 'semester': [1, 2], 'instructor': ['X', 'Y'], 'avg_grade': [75, 88]})\n",
    "wd = write_dataset('student_data', data_to_write, 'postgresql://postgres:root@localhost:5432/postgres')\n",
    "wd\n",
    "\n",
    "query = \"SELECT * FROM student_data\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191287c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets(engine):\n",
    "    query = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
    "    result = engine.execute(query)\n",
    "    tables = [row[0] for row in result]\n",
    "    return tables\n",
    "\n",
    "table_names = list_datasets(engine)\n",
    "print(\"Tables in the database:\\n\")\n",
    "for table in table_names:\n",
    "    print(\"-\",table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to delete particular table from database \n",
    "def delete_table(engine, table_name):       \n",
    "        delete_query = f\"DROP TABLE {table_name}\" \n",
    "        engine.execute(delete_query)\n",
    "        \n",
    "delete_table(engine, 'student_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2203b8",
   "metadata": {},
   "source": [
    "# DM-Practical-02  B - Association Rules \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ac7b7",
   "metadata": {},
   "source": [
    "### Q1: Transaction Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb4889",
   "metadata": {},
   "source": [
    "1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Online_Retail.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['InvoiceNo'] = data['InvoiceNo'].astype(str)\n",
    "data = data.dropna(subset=['Description', 'CustomerID'])\n",
    "data = data[~(data['InvoiceNo'].str.startswith('C') | data['InvoiceNo'].isnull())]\n",
    "data = data.reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1646c",
   "metadata": {},
   "source": [
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Description'] != 'POSTAGE']\n",
    "one_item = data['InvoiceNo'].value_counts() == 1\n",
    "data = data[~data['InvoiceNo'].isin(one_item[one_item].index)]\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6cf4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('output_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41435e43",
   "metadata": {},
   "source": [
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40681f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data['InvoiceDay'] = data['InvoiceDate'].dt.date\n",
    "data['InvoiceNo'] = data.groupby(['CustomerID', 'InvoiceDay'])['InvoiceNo'].transform('first')\n",
    "\n",
    "item_totals = data.groupby('StockCode')['Quantity'].sum()\n",
    "data = data[data['StockCode'].isin(item_totals[item_totals >= 1000].index)]\n",
    "data[['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3917c",
   "metadata": {},
   "source": [
    "4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "countData = data[data['Country'] == 'United Kingdom']\n",
    "countData\n",
    "\n",
    "# Count the number of UK records\n",
    "no_UK_records = len(countData)\n",
    "print(\"Number of records related to United Kingdom:\", no_UK_records) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95eaa90",
   "metadata": {},
   "source": [
    "5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = countData.groupby(['InvoiceNo', 'StockCode'])['Quantity'].sum().unstack(fill_value=0)\n",
    "transactions[transactions > 0] = 1\n",
    "transactions.reset_index(inplace=True)\n",
    "transactions.set_index('InvoiceNo', inplace=True)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94dca0",
   "metadata": {},
   "source": [
    "### Q2: Frequent Items and Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830b7e8",
   "metadata": {},
   "source": [
    "1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori algorithm min support = 0.02 \n",
    "transactions = transactions.applymap(lambda x: x > 0)\n",
    "freq_item_apriori = apriori(transactions, min_support=0.02, use_colnames=True)\n",
    "freq_item_apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4380b65",
   "metadata": {},
   "source": [
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP-Growth algorithm minimum support = 0.02\n",
    "freq_item_fpgrowth = fpgrowth(transactions, min_support=0.02, use_colnames=True)\n",
    "freq_item_fpgrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d6cf1",
   "metadata": {},
   "source": [
    "Apriori Algorithm: \n",
    "333 frequent itemsets in all were discovered.\n",
    "Single products make up a large portion of the frequent itemsets, indicating that single items are bought regularly.\n",
    "\n",
    "FP-Growth Algorithm: \n",
    "333 frequent itemsets in all were discovered.\n",
    "Because of its compact data format, FP-Growth performs better and is more effective when support is reasonably high.\n",
    "\n",
    "##### Conclusion:\n",
    "Above two algorithm discovered common itemsets that were comparable; \n",
    "However, FP-Growth showed that some items had more support. \n",
    "Which of these algorithms works best will depend on the specific dataset and performance requirements. \n",
    "FP-Growth is a great alternative for high-support itemset mining as it is more efficient in terms of execution time and memory managemnent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7762b88",
   "metadata": {},
   "source": [
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frequent_itemsets_apriori = apriori(transactions, min_support=0.02, use_colnames=True)\n",
    "\n",
    "association_rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "print(\"Scatter Plot\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(association_rules_apriori['support'], association_rules_apriori['confidence'], alpha=0.5)\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Confidence')\n",
    "plt.title('Support vs Confidence - Association Rules')\n",
    "plt.show()\n",
    "\n",
    "association_rules_apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bcaba",
   "metadata": {},
   "source": [
    "4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ee5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules - support > 0.028 (2.8%) & confidence > 0.5 (50%)\n",
    "important_rules = association_rules_apriori[(association_rules_apriori['support'] > 0.028) & (association_rules_apriori['confidence'] > 0.5)]\n",
    "print(\"Important Association Rules with Support > 0.028 and Confidence > 0.5 \")\n",
    "important_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a6f1d",
   "metadata": {},
   "source": [
    "#### Support: \n",
    "An itemset, or combination of items, is considered relatively common if its support is 0.028 or greater, meaning it appears in at least 2.8% of all transactions.\n",
    "#### Confidence: \n",
    "A confidence level of 0.5 or higher indicates that there is a 50% or greater chance that the consequent item will exist when the antecedent item is present. This suggests a robust correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c826c41",
   "metadata": {},
   "source": [
    "5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap - Most Important Association Rules\n",
    "pivot_table = important_rules.pivot(index = \"antecedents\", columns = \"consequents\", values = \"confidence\").fillna(0)\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "sns.heatmap(pivot_table, annot=True, cmap = \"YlGnBu\")\n",
    "plt.title(\"Heatmap - Most Important Association Rules \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68185c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
